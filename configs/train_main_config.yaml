# file: your_project_root/configs/train_main_config.yaml

defaults:
  - _self_
  - task: xarm_inspire_tabletop # 告诉Hydra去 configs/task/ 目录下查找 xarm_inspire_tabletop.yaml
  # - policy: diffusion_policy_default # 假设您有策略的默认配置
  # - training: default_training_params # 假设您有训练的默认配置
  # 您也可以在这里直接定义 policy 和 training 部分，或者也通过 defaults 引用它们

# Hydra 运行配置 (可以保留在我之前给您的示例中)
hydra:
  run:
    dir: ./outputs/train/${now:%Y-%m-%d_%H-%M-%S}_${task.name} # task.name 会从加载的 task 配置中获取
  sweep:
    dir: ./outputs/multirun/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}

# ---------- 策略配置 (Policy Configuration) ----------
policy:
  type: diffusion_unet_pointnet_transformer # 示例策略类型
  # ... (策略相关的其他参数，如vision_encoder, low_dim_state_encoder, denoising_network, num_diffusion_iters 等)
  # 例如:
  vision_encoder:
    type: pointnet_plus_plus_feat
    point_cloud_shape: ${task.shape_meta.obs.point_cloud} # 从task配置引用
    feat_dim: 128
  low_dim_state_encoder:
    type: mlp
    low_dim_state_shape: ${task.shape_meta.obs.low_dim_state} # 从task配置引用
    output_dim: 64
  denoising_network:
    type: conditional_unet_1d
    model_dim: 256
  num_diffusion_iters: 100

# ---------- 训练配置 (Training Configuration) ----------
training:
  optimizer: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-6
  # ... (其他训练参数，如 num_epochs, batch_size, use_ema, log_freq 等)
  num_epochs: 3000
  batch_size: 32
  use_ema: True
  log_freq: 100
  eval_freq: 1000
  save_freq: 5000
  seed: 42

# (其他全局配置或覆盖)